{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining and Search\n",
    "\n",
    "UniMiB 2022/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame(columns=['text','sentiment'])\n",
    "\n",
    "found = 0\n",
    "for file in tqdm(os.listdir('../data/raw/train/neg/')):\n",
    "  with io.open('../data/raw/train/neg/'+file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    train_dataset.loc[len(train_dataset)] = [text, 'NEG']\n",
    "for file in tqdm(os.listdir('../data/raw/train/pos/')):\n",
    "  with io.open('../data/raw/train/pos/'+file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    train_dataset.loc[len(train_dataset)] = [text, 'POS']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('../data/train_dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.DataFrame(columns=['text', 'sentiment'])\n",
    "\n",
    "found = 0\n",
    "for file in tqdm(os.listdir('../data/raw/test/neg/')):\n",
    "  with io.open('../data/raw/test/neg/'+file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    test_dataset.loc[len(test_dataset)] = [text, 'NEG']\n",
    "for file in tqdm(os.listdir('../data/raw/test/pos/')):\n",
    "  with io.open('../data/raw/test/pos/'+file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    test_dataset.loc[len(test_dataset)] = [text, 'POS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to_csv('../data/test_dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Story of a man who has unnatural feelings for ...       NEG\n",
       "1  Airport '77 starts as a brand new luxury 747 p...       NEG\n",
       "2  This film lacked something I couldn't put my f...       NEG\n",
       "3  Sorry everyone,,, I know this is supposed to b...       NEG\n",
       "4  When I was little my parents took me along to ...       NEG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_dataset.csv')\n",
    "train = train[['text', 'sentiment']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Once again Mr. Costner has dragged out a movie...       NEG\n",
       "1  This is an example of why the majority of acti...       NEG\n",
       "2  First of all I hate those moronic rappers, who...       NEG\n",
       "3  Not even the Beatles could write songs everyon...       NEG\n",
       "4  Brass pictures (movies is not a fitting word f...       NEG"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/test_dataset.csv')\n",
    "test = test[['text', 'sentiment']]\n",
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize('tests'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def remove_numbers(text_to_preprocess):\n",
    "    return re.sub(r'\\d+', '', text_to_preprocess)\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text[0].translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    no_stopwords = ''\n",
    "    for item in text.split():\n",
    "      if item not in stopwords.words():\n",
    "        no_stopwords+=' '+item\n",
    "    return no_stopwords\n",
    "\n",
    "\n",
    "def postagger(token_words):\n",
    "    return nltk.pos_tag(token_words)\n",
    "\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def tokenizer(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "def lemmatizer_function(tokenized_text):\n",
    "  lemmatized_text= ''\n",
    "  for token in tokenized_text:\n",
    "    lemmatized = lemmatizer.lemmatize(token)\n",
    "    lemmatized_text += ' '+lemmatized\n",
    "  return lemmatized_text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.str.lower()\n",
    "    no_nums = remove_numbers(text),\n",
    "    no_punct = remove_punctuation(no_nums)\n",
    "    no_stopw = remove_stopwords(no_punct)\n",
    "    no_whtspace = remove_extra_whitespace(no_stopw)\n",
    "    tokenized = tokenizer(no_whtspace)\n",
    "    lemmatized = lemmatizer_function(tokenized)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from preprocess import preprocess_loader\n",
    "if __name__ == '__main__':\n",
    "  df_split = np.array_split(train_ds, 10)\n",
    "  pool = Pool(10)\n",
    "  df = pd.concat(pool.map(preprocess_loader, df_split))\n",
    "  pool.close()\n",
    "  pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "train['preprocessed_text'] = train['text'].progress_apply(preprocess_text)\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>story unnatural feeling pig start opening sce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>airport start brand luxury plane loaded valua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>film lacked put finger charisma part leading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sorry supposed art film wow handed gun screen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>parent theater interior movie watched parent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  Story of a man who has unnatural feelings for ...       NEG   \n",
       "1  Airport '77 starts as a brand new luxury 747 p...       NEG   \n",
       "2  This film lacked something I couldn't put my f...       NEG   \n",
       "3  Sorry everyone,,, I know this is supposed to b...       NEG   \n",
       "4  When I was little my parents took me along to ...       NEG   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0   story unnatural feeling pig start opening sce...  \n",
       "1   airport start brand luxury plane loaded valua...  \n",
       "2   film lacked put finger charisma part leading ...  \n",
       "3   sorry supposed art film wow handed gun screen...  \n",
       "4   parent theater interior movie watched parent ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pp = pd.read_csv('../data/preprocessed_train.csv')\n",
    "train_pp = train_pp[['text', 'sentiment', 'preprocessed_text']]\n",
    "train_pp.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-Word (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer      #-- Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer      #-- Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = train_pp['preprocessed_text']\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),                                 #-- Uni-grams and Bi-grams\n",
    "                             max_features = 25000)                              #-- Most 25000 frequent grams across the text\n",
    "X_text_bow =  vectorizer.fit_transform(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "text_preprocessed = df_train['preprocessed_text']\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 25000)\n",
    "X_text_bow =  vectorizer.fit_transform(text_preprocessed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_text_bow.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_train_bow.save']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(X_text_bow, 'processed_train_bow.save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = train_pp['preprocessed_text']\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True, max_features = 25000)\n",
    "X_text_binary =  vectorizer.fit_transform(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 25000)\n"
     ]
    }
   ],
   "source": [
    "print(X_text_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_train_binary_bow.save']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(X_text_bow, 'processed_train_binary_bow.save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = train_pp['preprocessed_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=25000, ngram_range=(1, 2),)\n",
    "X_text_tfidf =  vectorizer.fit_transform(text_preprocessed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 25000)\n"
     ]
    }
   ],
   "source": [
    "print(X_text_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_train_tfidf.save']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(X_text_tfidf, 'processed_train_tfidf.save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified Linear Unit (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_pp['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_labels = encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load('processed_train_tfidf.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(25000))\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "prediction = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, prediction)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,encoded_labels,epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69059b0c3dc4947ea569f494d4ae19bc6a000e056abcbb0d417b4d8be3f88c1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
