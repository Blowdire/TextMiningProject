TMS

Text Classification
Dataset scelto: IMDB [http://ai.stanford.edu/~amaas/data/sentiment/]

Simili:

- [https://github.com/FrancescoFustini/Text-Mining]
- [https://github.com/simonetufano/Amazon_Reviews_Analysis]
- [https://github.com/malborroni/Good-or-Bad_Ask-your-Pet]

- [https://medium.com/nerd-for-tech/building-a-basic-binary-text-classifier-using-keras-4972a7c36616]
- [https://towardsdatascience.com/binary-classification-of-imdb-movie-reviews-648342bc70dd]
- [https://medium.com/@pyashpq56/sentiment-analysis-on-imdb-movie-review-d004f3e470bd]
- [https://humboldt-wi.github.io/blog/research/information_systems_1718/05sentimentanalysis/]
- [https://samyzaf.com/ML/imdb/imdb.html]
- [https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/code?datasetId=134715&sortBy=voteCount]
- [https://realpython.com/python-keras-text-classification/#what-is-a-word-embedding]
- [https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews]

Other popular choices for TC include:
- Boosted Decision Stumps (One level decision tree);
- Logistic Regression;
- Naive Bayesian Methods;
- Lazy Learning Methods (k-NN).

There are two important aspects to Evaluate a classifier: Efficiency, which refers to the consumption of computational resources (training and classification), and Effectiveness (Accuracy), that refers to how frequently classification decisions taken by a classifier are correct.

In classification by sentiment, bag of words is not enough, and deeper linguistic processing is necessary.

Note that those are different approaches with the same goal. Word2Vec achieves this by employing neural networks and GloVe achieves this with a co-occurrence matrix and by using matrix factorization. In both cases you are dealing with dimensionality reduction, but Word2Vec is more accurate and GloVe is faster to compute.